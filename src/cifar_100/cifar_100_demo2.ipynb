{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 10000, 10000, torch.Size([3, 32, 32]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from cifar_dataset import CIFAR100\n",
    "from utils.resnet_model import ResNet18, ResNet50, ResNet34\n",
    "import utils.skorch_trainer as skorch_trainer\n",
    "from torchvision.transforms import v2\n",
    "from utils.skorch_trainer import DataAug\n",
    "\n",
    "train_data = CIFAR100(split='train').dataset\n",
    "test_set = CIFAR100(split='test').dataset\n",
    "\n",
    "train_size = int(0.8 * len(train_data))\n",
    "test_size = len(train_data) - train_size\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(\n",
    "    CIFAR100(split='train').dataset, [train_size, test_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "len(train_set), len(val_set), len(test_set), train_set[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " New training:\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "lr = 0.1\n",
    "\n",
    "net_18_pure = skorch_trainer.net_def(\n",
    "    ResNet18, \n",
    "    net_name = '18_pure',\n",
    "    classes=[torch.tensor, torch.tensor],    \n",
    "    classifier_kwargs = dict(\n",
    "        lr = lr,\n",
    "        module__output_features = 100,\n",
    "        train_split = val_set,\n",
    "        callbacks = []\n",
    "    )\n",
    ")\n",
    "\n",
    "net_18_pure = skorch_trainer.net_fit(\n",
    "    net_18_pure, train_set, None, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 40\n",
    "lr = 0.01\n",
    "\n",
    "t1 = v2.Compose([\n",
    "    v2.RandomChoice([\n",
    "        v2.RandomPerspective(distortion_scale=0.1, p=0.8), \n",
    "        v2.RandomRotation(degrees=(0, 360))])\n",
    "])\n",
    "\n",
    "train_set_t1, _ = torch.utils.data.random_split(\n",
    "    CIFAR100(split='train', transform=t1).dataset, [train_size, test_size], \n",
    "    generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "net_18_t1 = skorch_trainer.net_def(\n",
    "    ResNet18, \n",
    "    net_name = '18_t2',\n",
    "    classes=[torch.tensor, torch.tensor],    \n",
    "    classifier_kwargs = dict(\n",
    "        lr = lr,\n",
    "        module__output_features = 100,\n",
    "        module__weights = None,\n",
    "        train_split = val_set,\n",
    "        batch_size = 1024,\n",
    "        callbacks = []\n",
    "    )\n",
    ")\n",
    "\n",
    "net_18_t1 = skorch_trainer.net_fit(\n",
    "    net_18_t1, train_set_t1, None, max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load saved params: 18_test_1_params.pt\n",
      "Histories:\n",
      "  epoch    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur\n",
      "-------  ------------  -----------  ----------  ------------  ----  ------  -------\n",
      "      1        \u001b[36m4.2010\u001b[0m       \u001b[32m0.0490\u001b[0m      \u001b[35m0.0458\u001b[0m        \u001b[31m4.4809\u001b[0m     +  0.1000  70.3854\n",
      "      2        \u001b[36m3.4543\u001b[0m       \u001b[32m0.1590\u001b[0m      \u001b[35m0.1416\u001b[0m        \u001b[31m3.5411\u001b[0m     +  0.1000  67.5431\n",
      "      3        \u001b[36m3.0922\u001b[0m       \u001b[32m0.1729\u001b[0m      \u001b[35m0.1614\u001b[0m        3.6213     +  0.1000  67.0053\n",
      "      4        \u001b[36m2.7750\u001b[0m       \u001b[32m0.2928\u001b[0m      \u001b[35m0.2918\u001b[0m        \u001b[31m2.9550\u001b[0m     +  0.1000  69.1558\n",
      "      5        \u001b[36m2.4832\u001b[0m       \u001b[32m0.2992\u001b[0m      0.2881        3.0181        0.1000  68.5017\n",
      "      6        \u001b[36m2.3963\u001b[0m       0.2600      0.2579        3.0554        0.1000  67.2076\n",
      "      7        \u001b[36m2.3404\u001b[0m       0.2881      0.2844        \u001b[31m2.8913\u001b[0m        0.1000  69.1046\n",
      "      8        \u001b[36m2.1058\u001b[0m       \u001b[32m0.3575\u001b[0m      \u001b[35m0.3492\u001b[0m        \u001b[31m2.7137\u001b[0m     +  0.1000  67.1878\n",
      "      9        \u001b[36m2.0162\u001b[0m       0.2710      0.2737        3.0702        0.1000  68.5860\n",
      "     10        \u001b[36m1.9524\u001b[0m       0.3277      0.3317        2.8251        0.1000  69.6921\n",
      "     11        \u001b[36m1.8877\u001b[0m       0.3018      0.3085        2.9433        0.1000  69.0855\n",
      "     12        \u001b[36m1.8743\u001b[0m       0.3558      \u001b[35m0.3522\u001b[0m        \u001b[31m2.6884\u001b[0m     +  0.1000  67.4730\n",
      "     13        \u001b[36m1.7971\u001b[0m       \u001b[32m0.3700\u001b[0m      \u001b[35m0.3645\u001b[0m        \u001b[31m2.6879\u001b[0m     +  0.1000  69.0771\n",
      "     14        \u001b[36m1.7242\u001b[0m       0.2516      0.2604        3.6286        0.1000  69.2067\n",
      "     15        \u001b[36m1.6012\u001b[0m       0.3642      0.3623        2.8154        0.1000  70.1963\n",
      "     16        \u001b[36m1.5425\u001b[0m       0.3512      0.3509        2.9315        0.1000  68.2948\n",
      "     17        \u001b[36m1.4053\u001b[0m       0.3436      0.3456        2.9113        0.1000  68.4896\n",
      "     18        \u001b[36m1.3410\u001b[0m       0.3418      0.3466        3.0722        0.1000  70.9913\n",
      "     19        \u001b[36m1.2523\u001b[0m       0.3339      0.3370        3.1627        0.1000  69.4194\n",
      "     20        \u001b[36m1.1704\u001b[0m       0.3434      0.3428        3.1409        0.1000  68.5765\n",
      "     21        \u001b[36m1.1478\u001b[0m       0.3405      0.3419        3.3200        0.1000  69.2410\n",
      "     22        \u001b[36m1.0426\u001b[0m       0.3515      0.3506        3.2352        0.1000  69.0221\n",
      "     23        \u001b[36m0.9633\u001b[0m       0.3414      0.3377        3.3384        0.1000  68.5203\n",
      "     24        \u001b[36m0.9282\u001b[0m       0.3441      0.3374        3.5761        0.1000  67.0728\n",
      "     25        \u001b[36m0.8404\u001b[0m       0.3602      0.3536        3.6190        0.1000  68.9892\n",
      "     26        \u001b[36m0.7740\u001b[0m       0.3395      0.3366        3.7455        0.1000  69.0692\n",
      "     27        \u001b[36m0.7251\u001b[0m       0.3310      0.3342        3.8519        0.1000  68.2653\n",
      "     28        \u001b[36m0.6973\u001b[0m       0.3521      0.3507        3.8928        0.1000  68.5246\n",
      "\n",
      "\n",
      " Continue training:\n",
      "  epoch    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur\n",
      "-------  ------------  -----------  ----------  ------------  ----  ------  -------\n",
      "     29        \u001b[36m0.3622\u001b[0m       \u001b[32m0.3790\u001b[0m      \u001b[35m0.3783\u001b[0m        \u001b[31m3.8660\u001b[0m     +  0.0100  69.6012\n",
      "     30        \u001b[36m0.2546\u001b[0m       \u001b[32m0.3815\u001b[0m      \u001b[35m0.3807\u001b[0m        3.9439     +  0.0100  67.4337\n",
      "     31        \u001b[36m0.2048\u001b[0m       \u001b[32m0.3820\u001b[0m      \u001b[35m0.3807\u001b[0m        4.0786     +  0.0100  66.8652\n",
      "     32        \u001b[36m0.1862\u001b[0m       \u001b[32m0.3853\u001b[0m      \u001b[35m0.3813\u001b[0m        4.2268     +  0.0100  66.9070\n",
      "     33        \u001b[36m0.1717\u001b[0m       0.3820      0.3780        4.3056        0.0100  66.9187\n",
      "     34        \u001b[36m0.1576\u001b[0m       0.3843      \u001b[35m0.3835\u001b[0m        4.2397     +  0.0100  66.2025\n",
      "     35        \u001b[36m0.1503\u001b[0m       \u001b[32m0.3880\u001b[0m      \u001b[35m0.3864\u001b[0m        4.2843     +  0.0100  67.5849\n",
      "     36        \u001b[36m0.1405\u001b[0m       0.3844      0.3826        4.3840        0.0100  68.1562\n",
      "     37        \u001b[36m0.1370\u001b[0m       0.3670      0.3690        4.5031        0.0100  68.1946\n",
      "     38        \u001b[36m0.1261\u001b[0m       0.3772      0.3783        4.4985        0.0100  67.1994\n",
      "     39        \u001b[36m0.1194\u001b[0m       0.3785      0.3782        4.5292        0.0100  66.0891\n",
      "     40        \u001b[36m0.1137\u001b[0m       0.3852      0.3847        4.5591        0.0100  67.9843\n",
      "     41        0.1157       0.3750      0.3750        4.5883        0.0100  71.7339\n"
     ]
    }
   ],
   "source": [
    "net_18_test_1 = skorch_trainer.net_def(\n",
    "    ResNet18, \n",
    "    net_name = '18_test_1',\n",
    "    classes=[torch.tensor, torch.tensor],    \n",
    "    classifier_kwargs = dict(\n",
    "        lr = 0.1,\n",
    "        module__output_features = 100,\n",
    "        module__weights = None,\n",
    "        train_split = val_set,\n",
    "        callbacks = [\n",
    "            DataAug(number_samples=5, p=0.75),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "net_18_test_1 = skorch_trainer.net_fit(\n",
    "    net_18_test_1, train_set, None, 50, new_lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load saved params: 18_test_2_params.pt\n",
      "Histories:\n",
      "  epoch    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur\n",
      "-------  ------------  -----------  ----------  ------------  ----  ------  --------\n",
      "      1        \u001b[36m4.3590\u001b[0m       \u001b[32m0.0883\u001b[0m      \u001b[35m0.0597\u001b[0m        \u001b[31m3.9389\u001b[0m     +  0.1000  139.3596\n",
      "      2        \u001b[36m3.7472\u001b[0m       \u001b[32m0.1604\u001b[0m      \u001b[35m0.1328\u001b[0m        \u001b[31m3.5306\u001b[0m     +  0.1000  140.4540\n",
      "      3        \u001b[36m3.3872\u001b[0m       \u001b[32m0.2000\u001b[0m      \u001b[35m0.1749\u001b[0m        \u001b[31m3.3332\u001b[0m     +  0.1000  140.8567\n",
      "      4        \u001b[36m3.1448\u001b[0m       \u001b[32m0.2437\u001b[0m      \u001b[35m0.2157\u001b[0m        \u001b[31m3.1264\u001b[0m     +  0.1000  136.6089\n",
      "      5        \u001b[36m2.8625\u001b[0m       \u001b[32m0.3017\u001b[0m      \u001b[35m0.2913\u001b[0m        \u001b[31m2.8108\u001b[0m     +  0.1000  138.4741\n",
      "      6        \u001b[36m2.6110\u001b[0m       \u001b[32m0.3489\u001b[0m      \u001b[35m0.3386\u001b[0m        \u001b[31m2.6117\u001b[0m     +  0.1000  137.8720\n",
      "      7        \u001b[36m2.3826\u001b[0m       \u001b[32m0.3931\u001b[0m      \u001b[35m0.3856\u001b[0m        \u001b[31m2.4196\u001b[0m     +  0.1000  139.0012\n",
      "      8        \u001b[36m2.1503\u001b[0m       \u001b[32m0.4155\u001b[0m      \u001b[35m0.4065\u001b[0m        \u001b[31m2.3264\u001b[0m     +  0.1000  139.4589\n",
      "      9        \u001b[36m1.9665\u001b[0m       \u001b[32m0.4196\u001b[0m      \u001b[35m0.4153\u001b[0m        \u001b[31m2.2877\u001b[0m     +  0.1000  139.7233\n",
      "     10        \u001b[36m1.7903\u001b[0m       \u001b[32m0.4415\u001b[0m      \u001b[35m0.4335\u001b[0m        \u001b[31m2.1535\u001b[0m     +  0.1000  140.4717\n",
      "     11        \u001b[36m1.6800\u001b[0m       0.4339      0.4304        2.2583        0.1000  132.9566\n",
      "     12        \u001b[36m1.5845\u001b[0m       \u001b[32m0.4685\u001b[0m      \u001b[35m0.4632\u001b[0m        \u001b[31m2.1256\u001b[0m     +  0.1000  136.8449\n",
      "     13        \u001b[36m1.4716\u001b[0m       0.4678      0.4614        2.1574        0.1000  136.8880\n",
      "     14        \u001b[36m1.4327\u001b[0m       0.4566      0.4524        2.2869        0.1000  137.7773\n",
      "     15        \u001b[36m1.3603\u001b[0m       0.4376      0.4384        2.4181        0.1000  138.2736\n",
      "     16        \u001b[36m1.2859\u001b[0m       0.4032      0.4027        2.8205        0.1000  138.4643\n",
      "     17        \u001b[36m1.1828\u001b[0m       0.4414      0.4374        2.5265        0.1000  130.3969\n",
      "     18        \u001b[36m1.1054\u001b[0m       0.4316      0.4260        2.6148        0.1000  129.3633\n",
      "     19        \u001b[36m0.9864\u001b[0m       0.4326      0.4303        2.6828        0.1000  134.0553\n",
      "     20        \u001b[36m0.9236\u001b[0m       0.4291      0.4263        2.7689        0.1000  130.0646\n",
      "     21        \u001b[36m1.0090\u001b[0m       \u001b[32m0.5332\u001b[0m      \u001b[35m0.5296\u001b[0m        \u001b[31m1.9454\u001b[0m     +  0.0100  136.4658\n",
      "     22        \u001b[36m0.8468\u001b[0m       0.5284      0.5252        1.9699        0.0100  135.2203\n",
      "     23        \u001b[36m0.7622\u001b[0m       0.5263      0.5228        2.0380        0.0100  135.2926\n",
      "     24        \u001b[36m0.7177\u001b[0m       0.5145      0.5114        2.1476        0.0100  136.0421\n",
      "     25        \u001b[36m0.6607\u001b[0m       0.5041      0.5005        2.2260        0.0100  135.6260\n",
      "     26        \u001b[36m0.6064\u001b[0m       0.5049      0.5024        2.3088        0.0100  131.0815\n",
      "     27        \u001b[36m0.5699\u001b[0m       0.5021      0.4999        2.4027        0.0100  136.7080\n",
      "     28        \u001b[36m0.5235\u001b[0m       0.4997      0.4971        2.4501        0.0100  135.7077\n",
      "     29        \u001b[36m0.4763\u001b[0m       0.4960      0.4939        2.5645        0.0100  135.9393\n",
      "     30        \u001b[36m0.4329\u001b[0m       0.4948      0.4928        2.6444        0.0100  138.7543\n",
      "     31        \u001b[36m0.8471\u001b[0m       0.5240      0.5212        \u001b[31m2.0003\u001b[0m        0.0100  132.1733\n",
      "     32        \u001b[36m0.7746\u001b[0m       0.5220      0.5186        2.0566        0.0100  130.5512\n",
      "     33        \u001b[36m0.7161\u001b[0m       0.5192      0.5157        2.1033        0.0100  130.3079\n",
      "     34        \u001b[36m0.6537\u001b[0m       0.5213      0.5178        2.2121        0.0100  130.0556\n",
      "     35        \u001b[36m0.6107\u001b[0m       0.5082      0.5048        2.2742        0.0100  130.3347\n",
      "     36        \u001b[36m0.5592\u001b[0m       0.4985      0.4955        2.3779        0.0100  132.5144\n",
      "     37        \u001b[36m0.5221\u001b[0m       0.5002      0.4973        2.4864        0.0100  130.4420\n",
      "     38        \u001b[36m0.4706\u001b[0m       0.4928      0.4907        2.5629        0.0100  138.2393\n",
      "     39        \u001b[36m0.4319\u001b[0m       0.4935      0.4904        2.6401        0.0100  134.1344\n",
      "     40        \u001b[36m0.3964\u001b[0m       0.4760      0.4750        2.7863        0.0100  135.0147\n",
      "     41        \u001b[36m0.8334\u001b[0m       \u001b[32m0.5389\u001b[0m      \u001b[35m0.5358\u001b[0m        \u001b[31m1.9320\u001b[0m     +  0.0010  132.8122\n",
      "     42        \u001b[36m0.8102\u001b[0m       0.5331      0.5305        1.9589        0.0010  131.2719\n",
      "     43        \u001b[36m0.7984\u001b[0m       0.5354      0.5334        1.9677        0.0010  131.4783\n",
      "     44        \u001b[36m0.7845\u001b[0m       0.5322      0.5284        1.9639        0.0010  132.3681\n",
      "     45        \u001b[36m0.7767\u001b[0m       0.5385      \u001b[35m0.5364\u001b[0m        1.9705     +  0.0010  132.4271\n",
      "     46        \u001b[36m0.7698\u001b[0m       0.5326      0.5300        1.9805        0.0010  138.7504\n",
      "     47        \u001b[36m0.7562\u001b[0m       0.5342      0.5310        1.9969        0.0010  140.8910\n",
      "     48        \u001b[36m0.7474\u001b[0m       0.5357      0.5326        1.9976        0.0010  139.5768\n",
      "     49        \u001b[36m0.7394\u001b[0m       0.5295      0.5271        2.0205        0.0010  142.1514\n",
      "     50        \u001b[36m0.7299\u001b[0m       0.5297      0.5269        2.0257        0.0010  141.7323\n",
      "\n",
      "\n",
      " Continue training:\n",
      "  epoch    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur\n",
      "-------  ------------  -----------  ----------  ------------  ----  ------  --------\n",
      "     51        \u001b[36m0.7648\u001b[0m       0.5304      0.5275        \u001b[31m1.9955\u001b[0m        0.0010  140.3374\n",
      "     52        \u001b[36m0.7568\u001b[0m       0.5333      0.5305        \u001b[31m1.9827\u001b[0m        0.0010  141.1504\n",
      "     53        \u001b[36m0.7421\u001b[0m       0.5310      0.5284        2.0341        0.0010  140.7489\n",
      "     54        \u001b[36m0.7388\u001b[0m       0.5290      0.5252        2.0132        0.0010  141.8831\n",
      "     55        \u001b[36m0.7369\u001b[0m       0.5322      0.5292        2.0019        0.0010  137.9646\n",
      "     56        \u001b[36m0.7273\u001b[0m       0.5293      0.5264        2.0342        0.0010  133.3702\n",
      "     57        \u001b[36m0.7173\u001b[0m       0.5286      0.5255        2.0234        0.0010  136.5993\n",
      "     58        \u001b[36m0.7078\u001b[0m       0.5294      0.5260        2.0419        0.0010  130.0850\n",
      "     59        \u001b[36m0.7017\u001b[0m       0.5315      0.5273        2.0502        0.0010  129.8502\n",
      "     60        \u001b[36m0.6949\u001b[0m       0.5303      0.5274        2.0635        0.0010  130.9869\n"
     ]
    }
   ],
   "source": [
    "net_18_test_2 = skorch_trainer.net_def(\n",
    "    ResNet18, \n",
    "    net_name = '18_test_2',\n",
    "    classes=[torch.tensor, torch.tensor],    \n",
    "    classifier_kwargs = dict(\n",
    "        lr = 0.1,\n",
    "        module__output_features = 100,\n",
    "        module__weights = None,\n",
    "        train_split = val_set,\n",
    "        callbacks = [\n",
    "            DataAug(number_samples=10, th=0.1, p=1),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "net_18_test_2 = skorch_trainer.net_fit(\n",
    "    net_18_test_2, train_set, None, 60, new_lr=0.001, load_best=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load saved params: 18_test_3_params.pt\n",
      "Histories:\n",
      "  epoch    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur\n",
      "-------  ------------  -----------  ----------  ------------  ----  ------  -------\n",
      "      1        \u001b[36m4.2574\u001b[0m       \u001b[32m0.1202\u001b[0m      \u001b[35m0.0877\u001b[0m        \u001b[31m3.7375\u001b[0m     +  0.1000  63.8545\n",
      "      2        \u001b[36m3.5982\u001b[0m       \u001b[32m0.1805\u001b[0m      \u001b[35m0.1558\u001b[0m        \u001b[31m3.3773\u001b[0m     +  0.1000  64.5239\n",
      "      3        \u001b[36m3.3002\u001b[0m       \u001b[32m0.2034\u001b[0m      \u001b[35m0.1892\u001b[0m        \u001b[31m3.2434\u001b[0m     +  0.1000  64.6936\n",
      "      4        \u001b[36m3.0555\u001b[0m       \u001b[32m0.2679\u001b[0m      \u001b[35m0.2511\u001b[0m        \u001b[31m2.9436\u001b[0m     +  0.1000  64.5847\n",
      "      5        \u001b[36m2.8417\u001b[0m       \u001b[32m0.2724\u001b[0m      \u001b[35m0.2636\u001b[0m        2.9695     +  0.1000  64.6195\n",
      "      6        \u001b[36m2.7171\u001b[0m       \u001b[32m0.3106\u001b[0m      \u001b[35m0.3003\u001b[0m        \u001b[31m2.7352\u001b[0m     +  0.1000  64.7121\n",
      "      7        \u001b[36m2.5489\u001b[0m       \u001b[32m0.3243\u001b[0m      \u001b[35m0.3121\u001b[0m        \u001b[31m2.6945\u001b[0m     +  0.1000  64.4163\n",
      "      8        \u001b[36m2.3856\u001b[0m       \u001b[32m0.3538\u001b[0m      \u001b[35m0.3470\u001b[0m        \u001b[31m2.5926\u001b[0m     +  0.1000  64.5267\n",
      "      9        \u001b[36m2.3085\u001b[0m       \u001b[32m0.3621\u001b[0m      \u001b[35m0.3505\u001b[0m        \u001b[31m2.5601\u001b[0m     +  0.1000  64.5878\n",
      "     10        \u001b[36m2.1119\u001b[0m       \u001b[32m0.3775\u001b[0m      \u001b[35m0.3698\u001b[0m        \u001b[31m2.5282\u001b[0m     +  0.1000  64.6614\n",
      "     11        \u001b[36m2.0105\u001b[0m       \u001b[32m0.4087\u001b[0m      \u001b[35m0.4025\u001b[0m        \u001b[31m2.4169\u001b[0m     +  0.1000  64.5168\n",
      "     12        \u001b[36m1.9023\u001b[0m       0.3824      0.3752        2.5628        0.1000  64.4661\n",
      "     13        \u001b[36m1.8052\u001b[0m       0.3855      0.3834        2.6069        0.1000  64.6957\n",
      "     14        \u001b[36m1.7156\u001b[0m       0.4014      0.3966        2.4898        0.1000  64.6028\n",
      "     15        \u001b[36m1.6285\u001b[0m       0.3922      0.3862        2.5281        0.1000  64.2051\n",
      "     16        \u001b[36m1.5630\u001b[0m       0.3857      0.3856        2.6056        0.1000  62.9501\n",
      "     17        \u001b[36m1.4684\u001b[0m       0.3889      0.3837        2.6842        0.1000  62.1269\n",
      "     18        \u001b[36m1.3918\u001b[0m       0.3862      0.3817        2.7490        0.1000  62.7745\n",
      "     19        \u001b[36m1.3310\u001b[0m       0.3797      0.3768        2.8094        0.1000  62.4789\n",
      "     20        \u001b[36m1.2418\u001b[0m       0.3750      0.3711        3.0796        0.1000  61.9476\n",
      "     21        \u001b[36m1.4730\u001b[0m       \u001b[32m0.4623\u001b[0m      \u001b[35m0.4586\u001b[0m        \u001b[31m2.1815\u001b[0m     +  0.0100  63.1458\n",
      "     22        \u001b[36m1.3231\u001b[0m       \u001b[32m0.4638\u001b[0m      \u001b[35m0.4617\u001b[0m        2.2209     +  0.0100  62.9698\n",
      "     23        \u001b[36m1.2554\u001b[0m       \u001b[32m0.4647\u001b[0m      0.4612        2.2061        0.0100  63.3274\n",
      "     24        \u001b[36m1.1897\u001b[0m       0.4647      \u001b[35m0.4618\u001b[0m        2.3301     +  0.0100  60.6918\n",
      "     25        \u001b[36m1.1485\u001b[0m       0.4615      0.4572        2.3278        0.0100  62.6730\n",
      "     26        \u001b[36m1.1041\u001b[0m       0.4577      0.4547        2.3424        0.0100  62.3263\n",
      "     27        \u001b[36m1.0695\u001b[0m       0.4531      0.4510        2.3832        0.0100  62.5006\n",
      "     28        \u001b[36m1.0249\u001b[0m       0.4526      0.4489        2.4452        0.0100  63.4542\n",
      "     29        \u001b[36m0.9888\u001b[0m       0.4253      0.4234        2.5986        0.0100  62.3915\n",
      "     30        1.0126       0.4346      0.4311        2.5998        0.0100  63.1069\n",
      "\n",
      "\n",
      " Continue training:\n",
      "  epoch    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur\n",
      "-------  ------------  -----------  ----------  ------------  ----  ------  -------\n",
      "     31        \u001b[36m1.1050\u001b[0m       0.4628      0.4599        \u001b[31m2.3044\u001b[0m        0.0010  62.7763\n",
      "     32        \u001b[36m1.0893\u001b[0m       0.4618      0.4601        2.3630        0.0010  62.4718\n",
      "     33        \u001b[36m1.0760\u001b[0m       \u001b[32m0.4650\u001b[0m      \u001b[35m0.4635\u001b[0m        2.4378     +  0.0010  62.4691\n",
      "     34        \u001b[36m1.0677\u001b[0m       0.4628      0.4595        2.3098        0.0010  62.5775\n",
      "     35        \u001b[36m1.0631\u001b[0m       0.4610      0.4571        2.3497        0.0010  61.0612\n",
      "     36        \u001b[36m1.0583\u001b[0m       \u001b[32m0.4651\u001b[0m      \u001b[35m0.4635\u001b[0m        2.3553     +  0.0010  61.8461\n",
      "     37        \u001b[36m1.0504\u001b[0m       0.4611      0.4588        2.3834        0.0010  62.1735\n",
      "     38        \u001b[36m1.0459\u001b[0m       0.4614      0.4587        2.4172        0.0010  62.4003\n",
      "     39        \u001b[36m1.0329\u001b[0m       0.4533      0.4501        2.4285        0.0010  62.4861\n",
      "     40        1.0388       0.4544      0.4528        2.4405        0.0010  62.4117\n"
     ]
    }
   ],
   "source": [
    "net_18_test_3 = skorch_trainer.net_def(\n",
    "    ResNet18, \n",
    "    net_name = '18_test_3',\n",
    "    classes=[torch.tensor, torch.tensor],    \n",
    "    classifier_kwargs = dict(\n",
    "        lr = 0.1,\n",
    "        module__output_features = 100,\n",
    "        module__weights = None,\n",
    "        train_split = val_set,\n",
    "        callbacks = [\n",
    "            DataAug(number_samples=3, th=0.1, p=1),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "net_18_test_3 = skorch_trainer.net_fit(\n",
    "    net_18_test_3, train_set, None, 40, new_lr = 0.001, load_best=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load saved params: 18_test_4_params.pt\n",
      "Histories:\n",
      "  epoch    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur\n",
      "-------  ------------  -----------  ----------  ------------  ----  ------  -------\n",
      "      1        \u001b[36m4.1642\u001b[0m       \u001b[32m0.0732\u001b[0m      \u001b[35m0.0594\u001b[0m        \u001b[31m4.1459\u001b[0m     +  0.1000  70.0652\n",
      "      2        \u001b[36m3.4982\u001b[0m       \u001b[32m0.1213\u001b[0m      \u001b[35m0.1185\u001b[0m        \u001b[31m3.7710\u001b[0m     +  0.1000  70.2317\n",
      "      3        \u001b[36m3.0407\u001b[0m       \u001b[32m0.1773\u001b[0m      \u001b[35m0.1754\u001b[0m        \u001b[31m3.3905\u001b[0m     +  0.1000  70.0554\n",
      "      4        \u001b[36m2.6815\u001b[0m       \u001b[32m0.2342\u001b[0m      \u001b[35m0.2297\u001b[0m        \u001b[31m3.1293\u001b[0m     +  0.1000  68.8142\n",
      "      5        \u001b[36m2.4300\u001b[0m       \u001b[32m0.2715\u001b[0m      \u001b[35m0.2697\u001b[0m        \u001b[31m2.9549\u001b[0m     +  0.1000  69.4995\n",
      "      6        \u001b[36m2.2872\u001b[0m       \u001b[32m0.3486\u001b[0m      \u001b[35m0.3451\u001b[0m        \u001b[31m2.6103\u001b[0m     +  0.1000  69.6286\n",
      "      7        \u001b[36m2.0931\u001b[0m       0.3459      \u001b[35m0.3494\u001b[0m        2.6252     +  0.1000  69.2546\n",
      "      8        \u001b[36m1.9390\u001b[0m       0.3440      0.3394        2.6690        0.1000  69.0941\n",
      "      9        \u001b[36m1.8973\u001b[0m       \u001b[32m0.3940\u001b[0m      \u001b[35m0.3927\u001b[0m        \u001b[31m2.4129\u001b[0m     +  0.1000  69.3488\n",
      "     10        \u001b[36m1.7598\u001b[0m       0.3856      0.3801        2.5612        0.1000  68.5375\n",
      "     11        1.7623       0.3752      0.3782        2.5492        0.1000  70.4119\n",
      "     12        \u001b[36m1.6050\u001b[0m       0.3887      0.3896        2.5194        0.1000  69.0449\n",
      "     13        \u001b[36m1.4999\u001b[0m       \u001b[32m0.4056\u001b[0m      \u001b[35m0.4066\u001b[0m        2.4725     +  0.1000  68.6667\n",
      "     14        \u001b[36m1.4233\u001b[0m       0.3959      0.3963        2.6025        0.1000  68.6204\n",
      "     15        \u001b[36m1.3334\u001b[0m       0.3842      0.3815        2.6072        0.1000  69.5783\n",
      "     16        \u001b[36m1.2645\u001b[0m       0.3959      0.3926        2.8097        0.1000  68.3101\n",
      "     17        \u001b[36m1.1951\u001b[0m       0.3975      0.3964        2.7331        0.1000  70.3634\n",
      "     18        \u001b[36m1.1307\u001b[0m       0.3790      0.3801        2.9173        0.1000  71.0405\n",
      "     19        \u001b[36m1.0510\u001b[0m       0.3672      0.3687        3.0573        0.1000  69.9343\n",
      "     20        \u001b[36m1.0005\u001b[0m       0.3789      0.3750        3.1545        0.1000  69.7800\n",
      "     21        \u001b[36m1.0173\u001b[0m       \u001b[32m0.4555\u001b[0m      \u001b[35m0.4563\u001b[0m        \u001b[31m2.3676\u001b[0m     +  0.0100  73.8920\n",
      "     22        \u001b[36m0.8711\u001b[0m       \u001b[32m0.4782\u001b[0m      \u001b[35m0.4778\u001b[0m        \u001b[31m2.3353\u001b[0m     +  0.0100  71.8029\n",
      "     23        \u001b[36m0.7873\u001b[0m       0.4464      0.4476        2.5128        0.0100  71.9306\n",
      "     24        \u001b[36m0.7428\u001b[0m       0.4467      0.4461        2.6407        0.0100  69.7898\n",
      "     25        \u001b[36m0.6961\u001b[0m       0.4288      0.4318        2.7739        0.0100  70.6238\n",
      "     26        \u001b[36m0.6579\u001b[0m       0.4298      0.4328        2.7200        0.0100  69.9084\n",
      "     27        \u001b[36m0.6135\u001b[0m       0.4352      0.4360        2.8506        0.0100  66.9860\n",
      "     28        \u001b[36m0.5865\u001b[0m       0.4166      0.4179        2.8975        0.0100  67.3770\n",
      "     29        \u001b[36m0.5431\u001b[0m       0.4329      0.4327        2.9355        0.0100  68.2065\n",
      "     30        \u001b[36m0.5142\u001b[0m       0.4534      0.4521        2.9424        0.0100  69.4665\n",
      "     31        \u001b[36m0.7941\u001b[0m       0.4522      0.4535        \u001b[31m2.5274\u001b[0m        0.0010  68.2869\n",
      "     32        \u001b[36m0.7671\u001b[0m       0.4422      0.4438        \u001b[31m2.5273\u001b[0m        0.0010  69.2896\n",
      "     33        \u001b[36m0.7585\u001b[0m       0.4439      0.4456        2.5290        0.0010  67.9551\n",
      "     34        \u001b[36m0.7384\u001b[0m       0.4545      0.4553        2.5534        0.0010  70.9558\n",
      "     35        \u001b[36m0.7374\u001b[0m       0.4279      0.4318        2.6032        0.0010  71.4916\n",
      "\n",
      "\n",
      " Continue training:\n",
      "  epoch    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur\n",
      "-------  ------------  -----------  ----------  ------------  ----  ------  -------\n",
      "     36        \u001b[36m0.7968\u001b[0m       0.4551      0.4547        \u001b[31m2.4889\u001b[0m        0.0100  70.0253\n",
      "     37        \u001b[36m0.7389\u001b[0m       0.4480      0.4485        2.6855        0.0100  69.0889\n",
      "     38        \u001b[36m0.6796\u001b[0m       0.4319      0.4329        2.6458        0.0100  71.9787\n",
      "     39        \u001b[36m0.6513\u001b[0m       0.4337      0.4350        2.6792        0.0100  70.6409\n",
      "     40        \u001b[36m0.6172\u001b[0m       0.4497      0.4498        2.7459        0.0100  70.8040\n",
      "     41        \u001b[36m0.5791\u001b[0m       0.4311      0.4323        2.8910        0.0100  70.5657\n",
      "     42        \u001b[36m0.5431\u001b[0m       0.4253      0.4264        2.8808        0.0100  70.1704\n",
      "     43        \u001b[36m0.5136\u001b[0m       0.4409      0.4409        2.9408        0.0100  70.6523\n",
      "     44        \u001b[36m0.4738\u001b[0m       0.4156      0.4175        3.0923        0.0100  68.3130\n",
      "     45        \u001b[36m0.4463\u001b[0m       0.4244      0.4274        3.0450        0.0100  71.4614\n",
      "     46        \u001b[36m0.4132\u001b[0m       0.4324      0.4320        3.1350        0.0100  70.0574\n",
      "     47        \u001b[36m0.3894\u001b[0m       0.3941      0.3994        3.5477        0.0100  68.5767\n",
      "     48        \u001b[36m0.3631\u001b[0m       0.4158      0.4167        3.4785        0.0100  67.5865\n",
      "     49        \u001b[36m0.3439\u001b[0m       0.4176      0.4190        3.4453        0.0100  67.0615\n",
      "     50        \u001b[36m0.3126\u001b[0m       0.4256      0.4230        3.9708        0.0100  70.1627\n"
     ]
    }
   ],
   "source": [
    "net_18_test_4 = skorch_trainer.net_def(\n",
    "    ResNet18, \n",
    "    net_name = '18_test_4',\n",
    "    classes=[torch.tensor, torch.tensor],    \n",
    "    classifier_kwargs = dict(\n",
    "        lr = 0.1,\n",
    "        module__output_features = 100,\n",
    "        module__weights = None,\n",
    "        train_split = val_set,\n",
    "        callbacks = [\n",
    "            DataAug(number_samples=5, th=0.1, p=0.75),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "net_18_test_4 = skorch_trainer.net_fit(\n",
    "    net_18_test_4, train_set, None, 50, new_lr=0.01, load_best=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load saved params: 18_test_5_params.pt\n",
      "Histories:\n",
      "  epoch    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur\n",
      "-------  ------------  -----------  ----------  ------------  ----  ------  -------\n",
      "      1        \u001b[36m4.1626\u001b[0m       \u001b[32m0.1244\u001b[0m      \u001b[35m0.0995\u001b[0m        \u001b[31m3.6623\u001b[0m     +  0.1000  81.3333\n",
      "      2        \u001b[36m3.5230\u001b[0m       \u001b[32m0.1760\u001b[0m      \u001b[35m0.1510\u001b[0m        \u001b[31m3.4180\u001b[0m     +  0.1000  81.8533\n",
      "      3        \u001b[36m3.2189\u001b[0m       \u001b[32m0.2637\u001b[0m      \u001b[35m0.2442\u001b[0m        \u001b[31m2.9290\u001b[0m     +  0.1000  81.9834\n",
      "      4        \u001b[36m2.9106\u001b[0m       0.2623      \u001b[35m0.2497\u001b[0m        3.0437     +  0.1000  81.6420\n",
      "      5        \u001b[36m2.7955\u001b[0m       \u001b[32m0.3306\u001b[0m      \u001b[35m0.3161\u001b[0m        \u001b[31m2.6727\u001b[0m     +  0.1000  80.9916\n",
      "      6        \u001b[36m2.5583\u001b[0m       \u001b[32m0.3402\u001b[0m      \u001b[35m0.3248\u001b[0m        \u001b[31m2.6241\u001b[0m     +  0.1000  81.6839\n",
      "      7        \u001b[36m2.3569\u001b[0m       \u001b[32m0.3579\u001b[0m      \u001b[35m0.3484\u001b[0m        \u001b[31m2.5627\u001b[0m     +  0.1000  82.7941\n",
      "      8        \u001b[36m2.1757\u001b[0m       \u001b[32m0.3824\u001b[0m      \u001b[35m0.3724\u001b[0m        \u001b[31m2.4473\u001b[0m     +  0.1000  82.7396\n",
      "      9        \u001b[36m2.0690\u001b[0m       \u001b[32m0.3949\u001b[0m      \u001b[35m0.3884\u001b[0m        \u001b[31m2.4091\u001b[0m     +  0.1000  80.1853\n",
      "     10        \u001b[36m1.9387\u001b[0m       \u001b[32m0.4093\u001b[0m      \u001b[35m0.4064\u001b[0m        \u001b[31m2.3472\u001b[0m     +  0.1000  80.6596\n",
      "     11        \u001b[36m1.8742\u001b[0m       0.3954      0.3866        2.4814        0.1000  80.1279\n",
      "     12        \u001b[36m1.7947\u001b[0m       \u001b[32m0.4145\u001b[0m      \u001b[35m0.4072\u001b[0m        2.4115     +  0.1000  80.5088\n",
      "     13        \u001b[36m1.6296\u001b[0m       0.4088      \u001b[35m0.4075\u001b[0m        2.4698     +  0.1000  81.0045\n",
      "     14        \u001b[36m1.5666\u001b[0m       0.3960      0.3889        2.5976        0.1000  83.6808\n",
      "     15        \u001b[36m1.4356\u001b[0m       0.4012      0.4004        2.5943        0.1000  84.2053\n",
      "     16        \u001b[36m1.3496\u001b[0m       0.3851      0.3800        2.7564        0.1000  84.5218\n",
      "     17        1.3629       0.3504      0.3435        2.9928        0.1000  84.1509\n",
      "     18        1.3928       0.3818      0.3797        2.8946        0.1000  83.7106\n",
      "     19        \u001b[36m1.1627\u001b[0m       0.3745      0.3715        3.0518        0.1000  82.5093\n",
      "     20        \u001b[36m1.0565\u001b[0m       0.3745      0.3738        3.1320        0.1000  80.8837\n",
      "     21        \u001b[36m1.0637\u001b[0m       \u001b[32m0.4624\u001b[0m      \u001b[35m0.4603\u001b[0m        \u001b[31m2.3328\u001b[0m     +  0.0100  80.4725\n",
      "     22        \u001b[36m0.8869\u001b[0m       0.4588      0.4583        2.4301        0.0100  79.7989\n",
      "     23        \u001b[36m0.8695\u001b[0m       0.4453      0.4433        2.5575        0.0100  79.8797\n",
      "     24        \u001b[36m0.8148\u001b[0m       0.4356      0.4342        2.7578        0.0100  79.7346\n",
      "     25        \u001b[36m0.7462\u001b[0m       0.4426      0.4413        2.6940        0.0100  80.1331\n",
      "     26        \u001b[36m0.6695\u001b[0m       0.4457      0.4439        2.7582        0.0100  79.9149\n",
      "     27        \u001b[36m0.6192\u001b[0m       0.4255      0.4236        2.9148        0.0100  80.3587\n",
      "     28        \u001b[36m0.5858\u001b[0m       0.4254      0.4257        3.0005        0.0100  80.7540\n",
      "     29        \u001b[36m0.5174\u001b[0m       0.4268      0.4258        3.0458        0.0100  81.3792\n",
      "     30        \u001b[36m0.4899\u001b[0m       0.4235      0.4220        3.1824        0.0100  81.9120\n",
      "     31        \u001b[36m0.8815\u001b[0m       0.4601      0.4598        \u001b[31m2.4019\u001b[0m        0.0010  81.5661\n",
      "     32        \u001b[36m0.8600\u001b[0m       0.4589      0.4574        \u001b[31m2.3934\u001b[0m        0.0010  82.5141\n",
      "     33        \u001b[36m0.8455\u001b[0m       0.4621      \u001b[35m0.4604\u001b[0m        2.4166     +  0.0010  82.1621\n",
      "     34        \u001b[36m0.8287\u001b[0m       \u001b[32m0.4641\u001b[0m      \u001b[35m0.4626\u001b[0m        2.4566     +  0.0010  81.2133\n",
      "     35        \u001b[36m0.8177\u001b[0m       0.4616      0.4599        2.4458        0.0010  79.6423\n",
      "     36        \u001b[36m0.8195\u001b[0m       0.4613      0.4600        \u001b[31m2.4593\u001b[0m        0.0010  81.2047\n",
      "     37        \u001b[36m0.8098\u001b[0m       0.4634      0.4613        \u001b[31m2.4303\u001b[0m        0.0010  80.6093\n",
      "     38        \u001b[36m0.7989\u001b[0m       0.4622      0.4608        2.4752        0.0010  81.2908\n",
      "     39        \u001b[36m0.7929\u001b[0m       0.4611      0.4604        2.4479        0.0010  81.6247\n",
      "     40        \u001b[36m0.7838\u001b[0m       \u001b[32m0.4648\u001b[0m      \u001b[35m0.4630\u001b[0m        2.4807     +  0.0010  81.6658\n",
      "     41        \u001b[36m0.7685\u001b[0m       \u001b[32m0.4652\u001b[0m      0.4626        \u001b[31m2.4987\u001b[0m        0.0010  82.1445\n",
      "     42        \u001b[36m0.7605\u001b[0m       0.4559      0.4538        2.4991        0.0010  81.8460\n",
      "     43        \u001b[36m0.7531\u001b[0m       0.4641      0.4622        2.5053        0.0010  82.3440\n",
      "     44        \u001b[36m0.7464\u001b[0m       0.4581      0.4574        2.5940        0.0010  83.4888\n",
      "     45        \u001b[36m0.7313\u001b[0m       0.4595      0.4579        2.6001        0.0010  83.2887\n",
      "\n",
      "\n",
      " Continue training:\n",
      "  epoch    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur\n",
      "-------  ------------  -----------  ----------  ------------  ----  ------  -------\n",
      "     46        \u001b[36m0.7693\u001b[0m       0.4641      0.4624        \u001b[31m2.4572\u001b[0m        0.0010  86.5705\n",
      "     47        \u001b[36m0.7691\u001b[0m       0.4604      0.4589        2.5133        0.0010  84.6318\n",
      "     48        \u001b[36m0.7466\u001b[0m       0.4599      0.4591        2.4999        0.0010  81.6640\n",
      "     49        \u001b[36m0.7402\u001b[0m       0.4588      0.4574        2.5101        0.0010  81.1554\n",
      "     50        \u001b[36m0.7329\u001b[0m       0.4581      0.4568        2.5534        0.0010  80.1356\n"
     ]
    }
   ],
   "source": [
    "net_18_test_5 = skorch_trainer.net_def(\n",
    "    ResNet18, \n",
    "    net_name = '18_test_5',\n",
    "    classes=[torch.tensor, torch.tensor],    \n",
    "    classifier_kwargs = dict(\n",
    "        lr = 0.1,\n",
    "        module__output_features = 100,\n",
    "        module__weights = None,\n",
    "        train_split = val_set,\n",
    "        callbacks = [\n",
    "            DataAug(number_samples=5, th=0.1, p=1),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "net_18_test_5 = skorch_trainer.net_fit(\n",
    "    net_18_test_5, train_set, None, 50, new_lr= 0.001, load_best=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load saved params: 18_test_6_params.pt\n",
      "Histories:\n",
      "  epoch    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur\n",
      "-------  ------------  -----------  ----------  ------------  ----  ------  -------\n",
      "      1        \u001b[36m4.2905\u001b[0m       \u001b[32m0.1149\u001b[0m      \u001b[35m0.0861\u001b[0m        \u001b[31m3.7698\u001b[0m     +  0.1000  80.2533\n",
      "      2        \u001b[36m3.6638\u001b[0m       \u001b[32m0.1551\u001b[0m      \u001b[35m0.1288\u001b[0m        \u001b[31m3.5864\u001b[0m     +  0.1000  79.7673\n",
      "      3        \u001b[36m3.4095\u001b[0m       \u001b[32m0.2028\u001b[0m      \u001b[35m0.1843\u001b[0m        \u001b[31m3.3103\u001b[0m     +  0.1000  79.7210\n",
      "      4        \u001b[36m3.1715\u001b[0m       \u001b[32m0.2451\u001b[0m      \u001b[35m0.2339\u001b[0m        \u001b[31m3.1382\u001b[0m     +  0.1000  79.8440\n",
      "      5        \u001b[36m2.9172\u001b[0m       \u001b[32m0.2973\u001b[0m      \u001b[35m0.2869\u001b[0m        \u001b[31m2.9308\u001b[0m     +  0.1000  79.9136\n",
      "      6        \u001b[36m2.7053\u001b[0m       \u001b[32m0.3202\u001b[0m      \u001b[35m0.3048\u001b[0m        \u001b[31m2.7669\u001b[0m     +  0.1000  82.9438\n",
      "      7        \u001b[36m2.5488\u001b[0m       \u001b[32m0.3676\u001b[0m      \u001b[35m0.3534\u001b[0m        \u001b[31m2.5203\u001b[0m     +  0.1000  84.3551\n",
      "      8        \u001b[36m2.3879\u001b[0m       0.3564      0.3495        2.5896        0.1000  82.3732\n",
      "      9        2.4110       0.3278      0.3179        2.7236        0.1000  83.2572\n",
      "     10        \u001b[36m2.2514\u001b[0m       \u001b[32m0.3906\u001b[0m      \u001b[35m0.3793\u001b[0m        \u001b[31m2.4706\u001b[0m     +  0.1000  84.7988\n",
      "     11        \u001b[36m2.1278\u001b[0m       \u001b[32m0.4016\u001b[0m      \u001b[35m0.3944\u001b[0m        \u001b[31m2.4364\u001b[0m     +  0.1000  83.1789\n",
      "     12        \u001b[36m1.9378\u001b[0m       0.3994      \u001b[35m0.3958\u001b[0m        \u001b[31m2.4113\u001b[0m     +  0.1000  81.3115\n",
      "     13        \u001b[36m1.8376\u001b[0m       0.4010      0.3934        2.5352        0.1000  81.6829\n",
      "     14        1.8669       0.3960      0.3872        2.5332        0.1000  80.6198\n",
      "     15        \u001b[36m1.7149\u001b[0m       0.3976      0.3910        2.5034        0.1000  80.6319\n",
      "     16        \u001b[36m1.6140\u001b[0m       \u001b[32m0.4053\u001b[0m      \u001b[35m0.4032\u001b[0m        2.5613     +  0.1000  80.5366\n",
      "     17        \u001b[36m1.5185\u001b[0m       0.3870      0.3790        2.8248        0.1000  82.4480\n",
      "     18        \u001b[36m1.4507\u001b[0m       0.3927      0.3872        2.6456        0.1000  80.4835\n",
      "     19        \u001b[36m1.3461\u001b[0m       0.3866      0.3824        2.8783        0.1000  80.1216\n",
      "     20        \u001b[36m1.2638\u001b[0m       0.3939      0.3913        2.8227        0.1000  80.1992\n",
      "     21        \u001b[36m1.0411\u001b[0m       \u001b[32m0.4460\u001b[0m      \u001b[35m0.4414\u001b[0m        \u001b[31m2.5273\u001b[0m     +  0.0100  80.6634\n",
      "     22        \u001b[36m0.8724\u001b[0m       \u001b[32m0.4535\u001b[0m      \u001b[35m0.4502\u001b[0m        2.5349     +  0.0100  79.8207\n",
      "     23        \u001b[36m0.7872\u001b[0m       0.4422      0.4399        2.6706        0.0100  79.8439\n",
      "     24        \u001b[36m0.7335\u001b[0m       0.4478      0.4437        2.6858        0.0100  79.8505\n",
      "     25        \u001b[36m0.6834\u001b[0m       0.4444      0.4429        2.7120        0.0100  80.1122\n",
      "     26        \u001b[36m0.6368\u001b[0m       0.4440      0.4407        2.8093        0.0100  80.0699\n",
      "     27        \u001b[36m0.5932\u001b[0m       0.4391      0.4372        2.9264        0.0100  80.1940\n",
      "     28        \u001b[36m0.5597\u001b[0m       0.4363      0.4341        3.0679        0.0100  80.3957\n",
      "     29        \u001b[36m0.5137\u001b[0m       0.4328      0.4304        3.1290        0.0100  79.9745\n",
      "     30        \u001b[36m0.4890\u001b[0m       0.4315      0.4288        3.3331        0.0100  79.9035\n",
      "\n",
      "\n",
      " Continue training:\n",
      "  epoch    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur\n",
      "-------  ------------  -----------  ----------  ------------  ----  ------  -------\n",
      "     31        \u001b[36m0.7711\u001b[0m       \u001b[32m0.4565\u001b[0m      \u001b[35m0.4530\u001b[0m        \u001b[31m2.5817\u001b[0m     +  0.0010  80.5097\n",
      "     32        \u001b[36m0.7548\u001b[0m       0.4511      0.4476        \u001b[31m2.5480\u001b[0m        0.0010  80.0708\n",
      "     33        \u001b[36m0.7439\u001b[0m       \u001b[32m0.4602\u001b[0m      \u001b[35m0.4567\u001b[0m        \u001b[31m2.5474\u001b[0m     +  0.0010  79.7520\n",
      "     34        \u001b[36m0.7397\u001b[0m       0.4549      0.4508        2.5831        0.0010  79.7893\n",
      "     35        \u001b[36m0.7204\u001b[0m       0.4529      0.4499        2.6115        0.0010  80.9066\n"
     ]
    }
   ],
   "source": [
    "net_18_test_6 = skorch_trainer.net_def(\n",
    "    ResNet18, \n",
    "    net_name = '18_test_6',\n",
    "    classes=[torch.tensor, torch.tensor],    \n",
    "    classifier_kwargs = dict(\n",
    "        lr = 0.1,\n",
    "        module__output_features = 100,\n",
    "        module__weights = None,\n",
    "        train_split = val_set,\n",
    "        callbacks = [\n",
    "            DataAug(number_samples=5, th=0.3, p=1),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "net_18_test_6 = skorch_trainer.net_fit(\n",
    "    net_18_test_6, train_set, None, 35, new_lr=0.001, load_best=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " New training:\n",
      "  epoch    train_loss    valid_acc    valid_f1    valid_loss    cp      lr      dur\n",
      "-------  ------------  -----------  ----------  ------------  ----  ------  -------\n",
      "      1        \u001b[36m4.3031\u001b[0m       \u001b[32m0.1034\u001b[0m      \u001b[35m0.0775\u001b[0m        \u001b[31m3.8544\u001b[0m     +  0.1000  81.8084\n",
      "      2        \u001b[36m3.6852\u001b[0m       \u001b[32m0.1610\u001b[0m      \u001b[35m0.1350\u001b[0m        \u001b[31m3.5238\u001b[0m     +  0.1000  80.9431\n",
      "      3        \u001b[36m3.3848\u001b[0m       \u001b[32m0.2112\u001b[0m      \u001b[35m0.1935\u001b[0m        \u001b[31m3.2458\u001b[0m     +  0.1000  81.6473\n",
      "      4        \u001b[36m3.1653\u001b[0m       0.2077      \u001b[35m0.1961\u001b[0m        3.3087     +  0.1000  80.7408\n",
      "      5        \u001b[36m2.9628\u001b[0m       \u001b[32m0.2930\u001b[0m      \u001b[35m0.2749\u001b[0m        \u001b[31m2.8169\u001b[0m     +  0.1000  79.9978\n",
      "      6        \u001b[36m2.6678\u001b[0m       \u001b[32m0.3073\u001b[0m      \u001b[35m0.2960\u001b[0m        \u001b[31m2.7817\u001b[0m     +  0.1000  81.7626\n",
      "      7        \u001b[36m2.5565\u001b[0m       0.2950      0.2851        2.8692        0.1000  80.1296\n",
      "      8        \u001b[36m2.5219\u001b[0m       \u001b[32m0.3174\u001b[0m      \u001b[35m0.3060\u001b[0m        2.7935     +  0.1000  79.9359\n",
      "      9        \u001b[36m2.3710\u001b[0m       \u001b[32m0.3347\u001b[0m      \u001b[35m0.3202\u001b[0m        \u001b[31m2.6917\u001b[0m     +  0.1000  79.8024\n",
      "     10        \u001b[36m2.2363\u001b[0m       \u001b[32m0.3661\u001b[0m      \u001b[35m0.3552\u001b[0m        \u001b[31m2.5769\u001b[0m     +  0.1000  79.9214\n",
      "     11        \u001b[36m2.1128\u001b[0m       0.3514      0.3450        \u001b[31m2.5749\u001b[0m        0.1000  80.1469\n",
      "     12        \u001b[36m2.0639\u001b[0m       0.3515      0.3456        2.6856        0.1000  80.0973\n",
      "     13        \u001b[36m1.9433\u001b[0m       0.3523      0.3449        2.7069        0.1000  79.9122\n",
      "     14        \u001b[36m1.8689\u001b[0m       0.3563      0.3514        2.6583        0.1000  80.4971\n",
      "     15        \u001b[36m1.7603\u001b[0m       0.3516      0.3439        2.8249        0.1000  80.8838\n",
      "     16        \u001b[36m1.6917\u001b[0m       0.3450      0.3407        3.0333        0.1000  83.4850\n",
      "     17        \u001b[36m1.5894\u001b[0m       0.3447      0.3401        2.9600        0.1000  83.1441\n",
      "     18        \u001b[36m1.5067\u001b[0m       0.3308      0.3269        3.0841        0.1000  81.5168\n",
      "     19        \u001b[36m1.4631\u001b[0m       0.3274      0.3249        3.3145        0.1000  81.8293\n",
      "     20        \u001b[36m1.3501\u001b[0m       0.3363      0.3351        3.2216        0.1000  81.3809\n"
     ]
    }
   ],
   "source": [
    "net_18_test_7 = skorch_trainer.net_def(\n",
    "    ResNet18, \n",
    "    net_name = '18_test_7',\n",
    "    classes=[torch.tensor, torch.tensor],    \n",
    "    classifier_kwargs = dict(\n",
    "        lr = 0.1,\n",
    "        module__output_features = 100,\n",
    "        module__weights = None,\n",
    "        train_split = val_set,\n",
    "        callbacks = [\n",
    "            DataAug(number_samples=5, th=0.7, p=1),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "net_18_test_7 = skorch_trainer.net_fit(\n",
    "    net_18_test_7, train_set, None, 20, load_best=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load saved params: 18_test_8_params.pt\n",
      "Histories:\n",
      "  epoch    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur\n",
      "-------  ------------  -----------  ----------  ------------  ----  ------  --------\n",
      "      1        \u001b[36m4.2135\u001b[0m       \u001b[32m0.1183\u001b[0m      \u001b[35m0.0925\u001b[0m        \u001b[31m3.8846\u001b[0m     +  0.1000  114.5282\n",
      "      2        \u001b[36m3.5326\u001b[0m       \u001b[32m0.1878\u001b[0m      \u001b[35m0.1661\u001b[0m        \u001b[31m3.3720\u001b[0m     +  0.1000  117.3779\n",
      "      3        \u001b[36m3.2599\u001b[0m       \u001b[32m0.2114\u001b[0m      \u001b[35m0.1912\u001b[0m        \u001b[31m3.2648\u001b[0m     +  0.1000  119.5108\n",
      "      4        \u001b[36m2.9836\u001b[0m       \u001b[32m0.2817\u001b[0m      \u001b[35m0.2635\u001b[0m        \u001b[31m2.8676\u001b[0m     +  0.1000  115.6632\n",
      "      5        \u001b[36m2.7255\u001b[0m       \u001b[32m0.3414\u001b[0m      \u001b[35m0.3276\u001b[0m        \u001b[31m2.6326\u001b[0m     +  0.1000  119.5449\n",
      "      6        \u001b[36m2.5465\u001b[0m       0.3010      0.2894        2.8241        0.1000  116.6128\n",
      "      7        \u001b[36m2.2796\u001b[0m       \u001b[32m0.3921\u001b[0m      \u001b[35m0.3857\u001b[0m        \u001b[31m2.4194\u001b[0m     +  0.1000  115.6344\n",
      "      8        \u001b[36m2.1684\u001b[0m       0.3809      0.3696        \u001b[31m2.4015\u001b[0m        0.1000  122.2044\n",
      "      9        \u001b[36m1.9799\u001b[0m       \u001b[32m0.4374\u001b[0m      \u001b[35m0.4314\u001b[0m        \u001b[31m2.1586\u001b[0m     +  0.1000  124.1382\n",
      "     10        \u001b[36m1.8018\u001b[0m       \u001b[32m0.4377\u001b[0m      0.4292        2.2473        0.1000  131.0310\n",
      "     11        \u001b[36m1.7378\u001b[0m       \u001b[32m0.4443\u001b[0m      \u001b[35m0.4411\u001b[0m        2.2146     +  0.1000  148.4791\n",
      "     12        \u001b[36m1.6897\u001b[0m       0.4263      0.4210        2.3533        0.1000  152.6656\n",
      "     13        \u001b[36m1.5271\u001b[0m       \u001b[32m0.4467\u001b[0m      \u001b[35m0.4429\u001b[0m        2.3225     +  0.1000  156.0398\n",
      "     14        \u001b[36m1.4628\u001b[0m       \u001b[32m0.4560\u001b[0m      \u001b[35m0.4496\u001b[0m        2.3114     +  0.1000  139.9927\n",
      "     15        \u001b[36m1.3959\u001b[0m       0.4170      0.4172        2.4748        0.1000  111.9321\n",
      "     16        \u001b[36m1.3206\u001b[0m       0.4418      0.4361        2.4385        0.1000  111.3802\n",
      "     17        \u001b[36m1.1781\u001b[0m       0.4297      0.4248        2.6430        0.1000  111.4957\n",
      "     18        \u001b[36m1.1160\u001b[0m       0.4227      0.4203        2.6499        0.1000  110.9853\n",
      "     19        \u001b[36m1.1094\u001b[0m       0.4074      0.4038        2.9516        0.1000  112.0117\n",
      "     20        \u001b[36m0.9767\u001b[0m       0.4125      0.4091        2.9012        0.1000  115.1320\n",
      "\n",
      "\n",
      " Continue training:\n",
      "  epoch    train_loss    valid_acc    valid_f1    valid_loss    cp      lr       dur\n",
      "-------  ------------  -----------  ----------  ------------  ----  ------  --------\n",
      "     21        \u001b[36m0.8838\u001b[0m       \u001b[32m0.4933\u001b[0m      \u001b[35m0.4906\u001b[0m        \u001b[31m2.2457\u001b[0m     +  0.0100  114.9917\n",
      "     22        \u001b[36m0.7209\u001b[0m       0.4863      0.4838        2.4401        0.0100  115.0037\n",
      "     23        \u001b[36m0.6560\u001b[0m       0.4731      0.4704        2.6376        0.0100  112.5199\n",
      "     24        \u001b[36m0.5965\u001b[0m       0.4765      0.4740        2.6726        0.0100  109.8250\n",
      "     25        \u001b[36m0.5444\u001b[0m       0.4725      0.4709        2.9067        0.0100  109.1684\n"
     ]
    }
   ],
   "source": [
    "net_18_t8 = skorch_trainer.net_def(\n",
    "    ResNet18, \n",
    "    net_name = '18_test_8',\n",
    "    classes=[torch.tensor, torch.tensor],    \n",
    "    classifier_kwargs = dict(\n",
    "        lr = 0.1,\n",
    "        module__output_features = 100,\n",
    "        module__weights = None,\n",
    "        train_split = val_set,\n",
    "        callbacks = [\n",
    "            DataAug(number_samples=8, th=0.1, p=1),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "net_18_t8 = skorch_trainer.net_fit(\n",
    "    net_18_t8, train_set, None, 25, new_lr=0.01, load_best=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xaifw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
