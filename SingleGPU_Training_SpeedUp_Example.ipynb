{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ACfRQg8Yew5I"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ICf9nN6fI0s",
        "outputId": "7c0efff7-9f33-41c0-a765-0adbdd3b678c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Download training data from open datasets\n",
        "\n",
        "mean_t = torch.tensor([0.485, 0.456, 0.406])\n",
        "std_t = torch.tensor([0.229, 0.224, 0.225])\n",
        "\n",
        "from torchvision.transforms import v2\n",
        "\n",
        "transform = v2.Compose([\n",
        "    v2.ToImage(),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Normalize(mean=mean_t, std=std_t),\n",
        "])\n",
        "\n",
        "training_data = datasets.CIFAR100(\n",
        "    root=\"data/cifar/\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform,\n",
        ")\n",
        "\n",
        "# Download test data from open datasets\n",
        "test_data = datasets.CIFAR100(\n",
        "    root=\"data/cifar/\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XJFjm3vfLaT",
        "outputId": "ec99dd81-7aa2-4421-c9b2-4a6c32893ffc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X [N, C, H, W]:  torch.Size([256, 3, 32, 32])\n",
            "Shape of y:  torch.Size([256]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256\n",
        "\n",
        "l_kws = dict(\n",
        "    num_workers = 1,\n",
        "    pin_memory = True,\n",
        "    persistent_workers=True,\n",
        "    prefetch_factor=32,\n",
        ")\n",
        "\n",
        "# Create data loaders\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size, **l_kws)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, **l_kws)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
        "    print(\"Shape of y: \", y.shape, y.dtype)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_RXcRopfO3q",
        "outputId": "69c6aba3-2d2b-47ff-a237-75d8f3fdf414"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using mps device\n"
          ]
        }
      ],
      "source": [
        "# Get cpu or gpu device for training\n",
        "def get_device(use_cpu=False):\n",
        "    return torch.device(\"cuda:0\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
        "\n",
        "device = get_device()\n",
        "print(\"Using {} device\".format(device))\n",
        "\n",
        "# Define model\n",
        "# class NeuralNetwork(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(NeuralNetwork, self).__init__()\n",
        "#         self.flatten = nn.Flatten()\n",
        "#         self.linear_relu_stack = nn.Sequential(\n",
        "#             nn.Linear(32*32*3, 512),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(512, 512),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(512, 100)\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.flatten(x)\n",
        "#         logits = self.linear_relu_stack(x)\n",
        "#         return logits\n",
        "\n",
        "# model = NeuralNetwork().to(device)\n",
        "# print(model)\n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "model = models.resnet50(\n",
        "            weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 100)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "B9S7az1bfQsm"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "# SGD momentum 0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_AkR6G9jfSPi"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/yinnnyou/anaconda3/envs/data_aug_3115/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "\n",
        "        # Compute prediction error\n",
        "        with torch.cuda.amp.autocast():\n",
        "          # loss = model(data)\n",
        "            pred = model(X)\n",
        "            loss = loss_fn(pred, y)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        # loss.backward()\n",
        "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 10)\n",
        "        # optimizer.step()\n",
        "\n",
        "        if (batch + 1) % 20 == 0:\n",
        "            # Unscales gradients and calls\n",
        "            # or skips optimizer.step()\n",
        "            scaler.step(optimizer)\n",
        "\n",
        "            # Updates the scale for next iteration\n",
        "            scaler.update()\n",
        "\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rVLmuFsbfUBl"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "def test(dataloader, model, loss_fn, st):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}. \", time.time() - st)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UqvWJkgRfVfW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/yinnnyou/anaconda3/envs/data_aug_3115/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 4.740006  [    0/50000]\n",
            "loss: 2.963702  [25600/50000]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/yinnnyou/workspace/medical_imaging_imbalancing/SingleGPU_Training_SpeedUp_Example.ipynb Cell 9\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yinnnyou/workspace/medical_imaging_imbalancing/SingleGPU_Training_SpeedUp_Example.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m-------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yinnnyou/workspace/medical_imaging_imbalancing/SingleGPU_Training_SpeedUp_Example.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     st \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yinnnyou/workspace/medical_imaging_imbalancing/SingleGPU_Training_SpeedUp_Example.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     train(train_dataloader, model, loss_fn, optimizer)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yinnnyou/workspace/medical_imaging_imbalancing/SingleGPU_Training_SpeedUp_Example.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     test(test_dataloader, model, loss_fn, st)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yinnnyou/workspace/medical_imaging_imbalancing/SingleGPU_Training_SpeedUp_Example.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone!\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;32m/Users/yinnnyou/workspace/medical_imaging_imbalancing/SingleGPU_Training_SpeedUp_Example.ipynb Cell 9\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yinnnyou/workspace/medical_imaging_imbalancing/SingleGPU_Training_SpeedUp_Example.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yinnnyou/workspace/medical_imaging_imbalancing/SingleGPU_Training_SpeedUp_Example.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch, (X, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yinnnyou/workspace/medical_imaging_imbalancing/SingleGPU_Training_SpeedUp_Example.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     X, y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yinnnyou/workspace/medical_imaging_imbalancing/SingleGPU_Training_SpeedUp_Example.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# Compute prediction error\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yinnnyou/workspace/medical_imaging_imbalancing/SingleGPU_Training_SpeedUp_Example.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mamp\u001b[39m.\u001b[39mautocast():\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yinnnyou/workspace/medical_imaging_imbalancing/SingleGPU_Training_SpeedUp_Example.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m       \u001b[39m# loss = model(data)\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "epochs = 200\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    st = time.time()\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn, st)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NizjEgNs9NA-"
      },
      "source": [
        "### Lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "yYiY6Awa9PJ0"
      },
      "outputs": [],
      "source": [
        "import lightning as L\n",
        "import torch.nn.functional as F\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "class LightModel(L.LightningModule):\n",
        "    def __init__(self, output_features, lr=1e-1,\n",
        "                 weights=models.ResNet50_Weights.IMAGENET1K_V1):\n",
        "        super().__init__()\n",
        "        model = models.resnet50(\n",
        "            weights=weights)\n",
        "        num_ftrs = model.fc.in_features\n",
        "        model.fc = nn.Linear(num_ftrs, output_features)\n",
        "        self.model = model\n",
        "        self.lr = lr\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        output = self.model(x)\n",
        "        loss = loss_fn.to(x.device)(output, y)\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    # def test_step(self, batch, batch_idx):\n",
        "    #     x, y = batch\n",
        "    #     output = self.model(x)\n",
        "    #     loss = F.mse_loss(torch.argmax(output), y)\n",
        "    #     self.log(\"test_loss\", loss, prog_bar=True)\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        output = self.model(x)\n",
        "        loss = loss_fn.to(x.device)(output, y)\n",
        "        self.log(\"val_loss\", loss)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # optimizer = torch.optim.SGD(\n",
        "        #     self.parameters(), lr=self.lr, momentum=0.9)\n",
        "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623,
          "referenced_widgets": [
            "297940c860e04813abcd12e1484ed53c",
            "58cd9979882445a7b610df06449aaeda",
            "da0f33560b62402cac14dc18898298d9",
            "ba8e785679dd46fa87d988a9e73a3ace",
            "01a48a278e654645884e0c2e66e22f56",
            "c37f429b519f4e908b5d1d7cc19e7feb",
            "80aa971331ee479fbe540a6f844d5346",
            "7f5696a8b34045d0a8e63e2f71efbb24",
            "a0eb42e454dc4e5fb15b5130c722e791",
            "b379f9e70f1c4882b11d2d256ecc579d",
            "0c0318c8c08044869d05829db127bd36"
          ]
        },
        "id": "pqlyNd2E90dp",
        "outputId": "80bccf57-dcc5-4541-824e-b17f2ea0bc45"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/Users/yinnnyou/anaconda3/envs/data_aug_3115/lib/python3.11/site-packages/lightning/pytorch/loops/utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
            "Missing logger folder: /Users/yinnnyou/workspace/medical_imaging_imbalancing/lightning_logs\n",
            "\n",
            "  | Name  | Type   | Params\n",
            "---------------------------------\n",
            "0 | model | ResNet | 23.7 M\n",
            "---------------------------------\n",
            "23.7 M    Trainable params\n",
            "0         Non-trainable params\n",
            "23.7 M    Total params\n",
            "94.852    Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/yinnnyou/anaconda3/envs/data_aug_3115/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                           \r"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/yinnnyou/anaconda3/envs/data_aug_3115/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7:  84%|████████▎ | 164/196 [00:27<00:05,  5.98it/s, v_num=0]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/yinnnyou/anaconda3/envs/data_aug_3115/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
          ]
        }
      ],
      "source": [
        "model = LightModel(output_features=100, lr=0.001)\n",
        "\n",
        "# train model\n",
        "trainer = L.Trainer()\n",
        "# tuner = Tuner(trainer)\n",
        "# lr_finder = tuner.lr_find(model, attr_name=\"lr\",\n",
        "            #   train_dataloaders=train_loader, val_dataloaders=valid_loader)\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size, **l_kws)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, **l_kws)\n",
        "\n",
        "# Plot with\n",
        "# fig = lr_finder.plot(suggest=True)\n",
        "# fig.show()\n",
        "trainer.fit(model=model,\n",
        "                train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01a48a278e654645884e0c2e66e22f56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "0c0318c8c08044869d05829db127bd36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "297940c860e04813abcd12e1484ed53c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58cd9979882445a7b610df06449aaeda",
              "IPY_MODEL_da0f33560b62402cac14dc18898298d9",
              "IPY_MODEL_ba8e785679dd46fa87d988a9e73a3ace"
            ],
            "layout": "IPY_MODEL_01a48a278e654645884e0c2e66e22f56"
          }
        },
        "58cd9979882445a7b610df06449aaeda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c37f429b519f4e908b5d1d7cc19e7feb",
            "placeholder": "​",
            "style": "IPY_MODEL_80aa971331ee479fbe540a6f844d5346",
            "value": "Epoch 8:  20%"
          }
        },
        "7f5696a8b34045d0a8e63e2f71efbb24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80aa971331ee479fbe540a6f844d5346": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0eb42e454dc4e5fb15b5130c722e791": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b379f9e70f1c4882b11d2d256ecc579d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba8e785679dd46fa87d988a9e73a3ace": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b379f9e70f1c4882b11d2d256ecc579d",
            "placeholder": "​",
            "style": "IPY_MODEL_0c0318c8c08044869d05829db127bd36",
            "value": " 40/196 [00:06&lt;00:26,  5.91it/s, v_num=1, train_loss=0.174]"
          }
        },
        "c37f429b519f4e908b5d1d7cc19e7feb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da0f33560b62402cac14dc18898298d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f5696a8b34045d0a8e63e2f71efbb24",
            "max": 196,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0eb42e454dc4e5fb15b5130c722e791",
            "value": 40
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
